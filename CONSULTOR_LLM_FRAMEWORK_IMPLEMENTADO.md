# Sistema Consultor LLM - Implementa√ß√£o Completa

## Resumo

Implementado sistema completo que transforma a LLM em um **consultor empresarial profissional** que conduz o cliente atrav√©s de um framework estruturado de 5 fases, sem "viajar na maionese".

---

## üéØ Problema Resolvido

**ANTES:**
- LLM gen√©rica que perguntava "Como posso ajudar?"
- Pedia informa√ß√µes j√° coletadas em formul√°rios
- N√£o seguia um processo estruturado
- "Viajava" para assuntos fora do escopo

**AGORA:**
- LLM age como consultor s√™nior que CONDUZ o processo
- NUNCA pede informa√ß√µes j√° coletadas
- Segue framework estruturado de 5 fases
- Explica cada entreg√°vel antes de avan√ßar
- Aguarda valida√ß√£o do cliente em cada checkpoint
- Usa CTAs contextualizados para guiar a conversa

---

## üèóÔ∏è Arquitetura Implementada

### 1. **IntelligentPromptBuilder** (`intelligent-prompt-builder.ts`)

Constr√≥i prompts detalhados e espec√≠ficos por fase que incluem:

**Identidade do Consultor:**
- Consultor s√™nior em transforma√ß√£o empresarial
- Especialista em diagn√≥stico, mapeamento BPMN, frameworks estrat√©gicos
- Comunica√ß√£o profissional, direta, educacional e consultiva

**Framework Completo de 5 Fases:**
- **FASE 1 - APRESENTA√á√ÉO/ANAMNESE**: Conhecer empresa e desafios
- **FASE 2 - MODELAGEM**: Business Model Canvas + Cadeia de Valor
- **FASE 3 - PRIORIZA√á√ÉO**: Matriz de prioriza√ß√£o de processos
- **FASE 4 - EXECU√á√ÉO**: Mapeamento AS-IS + Diagn√≥stico + Plano 5W2H
- **FASE 5 - ACOMPANHAMENTO**: Kanban interativo

**Instru√ß√µes Espec√≠ficas por Fase:**
- Prompts diferentes para cada etapa_atual
- Sub-instru√ß√µes baseadas em aguardando_validacao
- CTAs contextualizados para cada momento

**Contexto Completo:**
- Todos os dados j√° coletados (contexto_coleta)
- Hist√≥rico de entreg√°veis gerados
- Status de gamifica√ß√£o (XP, n√≠vel, conquistas)
- √öltimas 5 mensagens da conversa

**Regras Cr√≠ticas:**
- NUNCA perguntar dados j√° em contexto_coleta
- NUNCA avan√ßar fase sem explicar entreg√°veis
- SEMPRE usar CTA contextualizado ao final
- SEMPRE aguardar valida√ß√£o do cliente
- SEMPRE analisar dados ap√≥s receber formul√°rios

### 2. **MarkerProcessor** (`marker-processor.ts`)

Sistema de marcadores que a LLM usa para acionar a√ß√µes:

**Marcadores Dispon√≠veis:**
```
[EXIBIR_FORMULARIO:tipo]     ‚Üí Exibe formul√°rio ao cliente
[GERAR_ENTREGAVEL:tipo]       ‚Üí Gera documento HTML customizado
[SET_VALIDACAO:tipo]          ‚Üí Define estado de aguardando_validacao
[AVANCAR_FASE:fase]           ‚Üí Avan√ßa para pr√≥xima fase
[GAMIFICACAO:evento:xp]       ‚Üí Concede XP (opcional, auto-detectado)
```

**Processamento:**
1. Detecta marcadores na resposta da LLM
2. Extrai a√ß√µes a executar
3. Remove marcadores do texto exibido ao usu√°rio
4. Executa a√ß√µes no banco (atualiza jornada, timeline, gamifica√ß√£o)
5. Retorna conte√∫do limpo + lista de a√ß√µes

**Auto-Award de XP:**
- Formul√°rio preenchido: +50 XP
- Entreg√°vel gerado: +75 XP
- Fase conclu√≠da: +100 XP
- A√ß√£o iniciada: +25 XP

### 3. **DeliverableGenerator** (`deliverable-generator.ts`)

Gera√ß√£o de documentos HTML customizados via LLM:

**Tipos de Entreg√°veis:**
1. **Anamnese Empresarial** - Perfil completo, problemas ocultos por √°rea
2. **Business Model Canvas** - Canvas visual com 9 blocos + an√°lise
3. **Cadeia de Valor (Porter)** - Atividades prim√°rias/suporte + an√°lise
4. **Matriz de Prioriza√ß√£o** - Matriz 2x2 (Impacto x Esfor√ßo) + processos priorizados
5. **Mapeamento AS-IS (BPMN)** - Fluxo visual com gargalos destacados
6. **Diagn√≥stico Detalhado** - Problemas, causas raiz, impacto, riscos
7. **Plano de A√ß√£o 5W2H** - Tabela completa com a√ß√µes priorizadas

**Processo:**
1. LLM principal usa marcador: `[GERAR_ENTREGAVEL:canvas]`
2. Sistema faz **segunda chamada √† LLM** com prompt especializado
3. Prompt inclui: dados do contexto_coleta + requisitos de formato
4. LLM gera HTML completo com CSS embarcado
5. HTML √© limpo e validado
6. Salvo em `entregaveis_consultor` table

### 4. **Sistema de CTAs Contextualizados**

Cada resposta da LLM termina com CTA que:
- Oferece pr√≥ximos passos claros
- Usa escolhas quando apropriado: (a) op√ß√£o 1 ou (b) op√ß√£o 2
- Solicita confirma√ß√£o antes de avan√ßar
- Mant√©m cliente engajado e no controle

**Exemplos de CTAs:**
- Apresenta√ß√£o: "Gostaria de (a) entender o m√©todo ou (b) come√ßar imediatamente?"
- P√≥s-formul√°rio: "Analisei seu perfil. Quer detalhes ou seguimos para o Canvas?"
- P√≥s-entreg√°vel: "Gerei 3 documentos. Leia e me confirme se est√° claro para seguirmos."
- Valida√ß√£o: "Concorda com essa an√°lise ou quer ajustar algo?"

### 5. **Sistema de Valida√ß√£o de Checkpoint**

Campo `aguardando_validacao` na tabela `jornadas_consultor`:

**Estados Poss√≠veis:**
- `anamnese` - Aguardando cliente ler anamnese gerada
- `modelagem` - Aguardando cliente validar Canvas + Cadeia de Valor
- `priorizacao` - Aguardando cliente confirmar matriz de prioriza√ß√£o
- `bpmn` - Aguardando cliente validar mapeamento AS-IS
- `diagnostico` - Aguardando cliente processar diagn√≥stico
- `plano_acao` - Aguardando cliente validar plano de a√ß√£o

**Fluxo:**
1. LLM gera entreg√°vel
2. LLM usa `[SET_VALIDACAO:tipo]`
3. Campo `aguardando_validacao` √© setado
4. LLM explica o entreg√°vel
5. LLM aguarda resposta do cliente
6. Cliente valida (confirma entendimento)
7. LLM explica pr√≥xima fase
8. LLM usa `[AVANCAR_FASE:nome]`
9. Campo `aguardando_validacao` √© limpo
10. Campo `etapa_atual` √© atualizado

### 6. **Gamifica√ß√£o por Conversa**

Tabela `gamificacao_conversa` (n√£o por usu√°rio):

**Campos:**
- `conversation_id` - Chave √∫nica
- `xp_total` - XP acumulado nesta conversa
- `nivel` - N√≠vel atual (200 XP = 1 n√≠vel)
- `conquistas` - Array de conquistas com timestamp
- `ultima_atualizacao`

**Caracter√≠sticas:**
- **Zera automaticamente** em nova conversa
- XP √© mencionado naturalmente pela LLM
- Exemplo: "Excelente! +50 XP por completar a anamnese. Est√° no n√≠vel 2!"

**Fun√ß√£o RPC:**
```sql
add_xp_to_conversation(p_conversation_id, p_xp_amount, p_conquista_nome)
```

### 7. **Timeline Autom√°tica**

Tabela `timeline_consultor` registra eventos automaticamente:

**Eventos Registrados:**
- In√≠cio de nova fase
- Conclus√£o de fase
- Gera√ß√£o de entreg√°vel
- Marcos importantes

**Fun√ß√£o RPC:**
```sql
add_timeline_event(p_jornada_id, p_evento, p_fase)
```

---

## üìä Banco de Dados - Altera√ß√µes

### Migration Aplicada: `add_consultor_validation_flow_and_conversation_gamification`

**Tabela `jornadas_consultor` - Novos Campos:**
```sql
aguardando_validacao text   -- Estado de valida√ß√£o atual
contexto_coleta jsonb        -- Todos os dados coletados (j√° existia, confirmado)
```

**Nova Tabela `gamificacao_conversa`:**
```sql
id uuid PRIMARY KEY
conversation_id uuid UNIQUE  -- FK to conversations
xp_total integer DEFAULT 0
nivel integer DEFAULT 1
conquistas jsonb DEFAULT '[]'
ultima_atualizacao timestamptz
```

**Nova Tabela `timeline_consultor`:**
```sql
id uuid PRIMARY KEY
jornada_id uuid              -- FK to jornadas_consultor
evento text                  -- Event description
fase text                    -- Phase when event occurred
timestamp timestamptz
```

**Fun√ß√µes RPC Criadas:**
- `add_xp_to_conversation()` - Adiciona XP e calcula level up
- `add_timeline_event()` - Registra evento na timeline

**RLS Policies:**
- Usu√°rios acessam apenas suas pr√≥prias conversas/jornadas
- Todas as tabelas protegidas com RLS

---

## üîÑ Fluxo Completo (Exemplo)

### 1. Primeira Mensagem (Apresenta√ß√£o)
**Cliente:** "Ol√°"

**Sistema:**
- Cria `jornadas_consultor` com `etapa_atual='apresentacao'`
- Cria `gamificacao_conversa` com XP=0, N√≠vel=1
- Chama LLM com prompt de apresenta√ß√£o

**LLM Responde:**
```
Ol√°! Sou o Proceda Consultor IA, especialista em transforma√ß√£o empresarial.

Vou te guiar por um m√©todo estruturado de 5 fases para elevar sua empresa ao pr√≥ximo n√≠vel:

üìã FASE 1 - ANAMNESE
üé® FASE 2 - MODELAGEM GERAL
üéØ FASE 3 - PRIORIZA√á√ÉO
‚öôÔ∏è FASE 4 - EXECU√á√ÉO
üìä FASE 5 - ACOMPANHAMENTO

Pronto para come√ßar? (Responda qualquer coisa para iniciar)
```

### 2. Cliente Aceita Iniciar
**Cliente:** "Sim, vamos come√ßar"

**LLM Responde:**
```
Perfeito! Vamos come√ßar pela Fase 1: Anamnese Empresarial.

Vou enviar um formul√°rio r√°pido (3 minutos) para conhecer voc√™ e sua empresa.

[EXIBIR_FORMULARIO:anamnese]
```

**Sistema:**
- Detecta marcador `[EXIBIR_FORMULARIO:anamnese]`
- Remove marcador do texto exibido
- Envia a√ß√£o `exibir_formulario` ao frontend
- Frontend exibe formul√°rio de anamnese

### 3. Cliente Preenche Formul√°rio
**Cliente submete:**
```json
{
  "nome_empresa": "TechSolutions",
  "setor": "Tecnologia",
  "desafio_principal": "Baixa produtividade"
}
```

**Sistema:**
- Detecta `form_data` no request
- Atualiza `contexto_coleta` com dados
- Concede +50 XP automaticamente
- Chama LLM com contexto atualizado

**LLM Responde:**
```
Excelente! Voc√™ ganhou 50 XP! Est√° no n√≠vel 1 (faltam 150 XP para o n√≠vel 2).

Analisando seu perfil:
- Empresa: TechSolutions (Setor Tecnologia)
- Desafio: Baixa produtividade

Identifiquei alguns problemas ocultos:
- **Opera√ß√µes**: Poss√≠vel falta de automa√ß√£o em processos manuais
- **RH**: Pode haver gap de capacita√ß√£o t√©cnica
- **Gest√£o**: M√©tricas de produtividade podem n√£o estar claras

Vamos agora estruturar seu modelo de neg√≥cio com o Business Model Canvas.

[EXIBIR_FORMULARIO:canvas]

Posso enviar o formul√°rio do Canvas?
```

### 4. Cliente Preenche Canvas
**Cliente submete dados do Canvas**

**Sistema:**
- Atualiza contexto_coleta
- +50 XP
- Chama LLM

**LLM Responde:**
```
√ìtimo! Mais 50 XP! Total: 100 XP (n√≠vel 1, faltam 100 XP para n√≠vel 2).

Agora vou gerar 3 documentos estrat√©gicos:

[GERAR_ENTREGAVEL:anamnese]
[GERAR_ENTREGAVEL:canvas]
[GERAR_ENTREGAVEL:cadeia_valor]
[SET_VALIDACAO:modelagem]

Gerei 3 documentos na aba "Entreg√°veis":

1. **Anamnese Empresarial**: Mostra que a TechSolutions enfrenta baixa produtividade por falta de automa√ß√£o. Recomendo focar em processos cr√≠ticos.

2. **Business Model Canvas**: Revela que sua proposta de valor est√° clara, mas os processos-chave precisam de otimiza√ß√£o.

3. **Cadeia de Valor**: Indica que as opera√ß√µes (desenvolvimento) s√£o onde mais valor √© criado, mas tamb√©m onde h√° mais desperd√≠cio.

Leia com aten√ß√£o os 3 documentos. Alguma d√∫vida ou podemos seguir para a prioriza√ß√£o dos processos?
```

**Sistema:**
- Detecta 3 marcadores `[GERAR_ENTREGAVEL]`
- Para cada um, faz chamada LLM especializada
- Gera HTML customizado com dados do contexto
- Salva em `entregaveis_consultor`
- +75 XP por cada entreg√°vel (total +225 XP)
- Detecta `[SET_VALIDACAO:modelagem]`
- Seta `aguardando_validacao='modelagem'`
- Remove marcadores do texto exibido

### 5. Cliente Valida
**Cliente:** "OK, li tudo e est√° claro"

**Sistema:**
- LLM recebe contexto: "Aguardando valida√ß√£o de: modelagem"
- LLM sabe que cliente validou

**LLM Responde:**
```
Perfeito! Subiu de n√≠vel! üéâ Agora voc√™ est√° no n√≠vel 2! (XP: 375)

Vamos para a Fase 3: Prioriza√ß√£o.

Vou aplicar uma Matriz de Prioriza√ß√£o (Impacto x Esfor√ßo) nos processos identificados. Isso vai revelar quais processos devemos atacar primeiro para gerar resultados r√°pidos.

[AVANCAR_FASE:priorizacao]

Um momento enquanto analiso e gero a matriz...
```

**Sistema:**
- Detecta `[AVANCAR_FASE:priorizacao]`
- Atualiza `etapa_atual='priorizacao'`
- Limpa `aguardando_validacao` (null)
- Adiciona evento na `timeline_consultor`
- +100 XP por conclus√£o de fase
- Level up detectado (400 XP = n√≠vel 2)

### 6. Continua Fluxo...
O processo continua com:
- Gera√ß√£o de matriz de prioriza√ß√£o
- Valida√ß√£o da prioriza√ß√£o
- Mapeamento AS-IS do processo priorit√°rio
- Diagn√≥stico detalhado
- Plano de a√ß√£o 5W2H
- Kanban de execu√ß√£o

Cada etapa:
1. LLM explica o que vai fazer
2. LLM gera entreg√°vel
3. LLM explica o entreg√°vel gerado
4. LLM aguarda valida√ß√£o com CTA
5. Cliente valida
6. LLM explica pr√≥xima fase
7. LLM avan√ßa fase

---

## ‚úÖ Resultados Alcan√ßados

### O que foi eliminado:
- ‚ùå LLM perguntando "Como posso ajudar?"
- ‚ùå LLM pedindo informa√ß√µes j√° coletadas
- ‚ùå LLM "viajando" para assuntos fora do framework
- ‚ùå Respostas gen√©ricas sem direcionamento
- ‚ùå Avan√ßo de fase sem explica√ß√£o

### O que foi implementado:
- ‚úÖ LLM age como consultor que CONDUZ o processo
- ‚úÖ Framework estruturado de 5 fases sempre seguido
- ‚úÖ Contexto completo passado em cada chamada
- ‚úÖ Nunca pede dados j√° coletados
- ‚úÖ Explica cada entreg√°vel antes de avan√ßar
- ‚úÖ Aguarda valida√ß√£o do cliente em checkpoints
- ‚úÖ CTAs contextualizados guiam a conversa
- ‚úÖ Gamifica√ß√£o natural e por conversa
- ‚úÖ Timeline autom√°tica de eventos
- ‚úÖ Gera√ß√£o de documentos HTML customizados
- ‚úÖ Sistema de marcadores para a√ß√µes

---

## üìÅ Arquivos Criados/Modificados

### Novos Arquivos:
1. `/supabase/functions/consultor-chat/intelligent-prompt-builder.ts` - Sistema de prompts
2. `/supabase/functions/consultor-chat/marker-processor.ts` - Processador de marcadores
3. `/supabase/functions/consultor-chat/deliverable-generator.ts` - Gerador de entreg√°veis

### Modificados:
1. `/supabase/functions/consultor-chat/index.ts` - Integra√ß√£o completa

### Migration:
1. `/supabase/migrations/[timestamp]_add_consultor_validation_flow_and_conversation_gamification.sql`

---

## üöÄ Pr√≥ximos Passos (Deployment)

### Para Deploy das Edge Functions:

Os arquivos modulares foram criados em:
```
/supabase/functions/consultor-chat/
  - index.ts
  - intelligent-prompt-builder.ts
  - marker-processor.ts
  - deliverable-generator.ts
```

**Op√ß√£o 1: Deploy via Supabase CLI** (Recomendado)
```bash
supabase functions deploy consultor-chat
```

**Op√ß√£o 2: Consolidar em arquivo √∫nico**
Se houver problemas com imports, consolidar os 3 m√≥dulos dentro do `index.ts` em um √∫nico arquivo.

### Vari√°vel de Ambiente Necess√°ria:
```
OPENAI_API_KEY=sk-...
```
(J√° est√° configurada no Supabase via dashboard)

---

## üéì Como Funciona o Sistema

### Prompt System:
- **Tamanho**: 5.000-8.000 caracteres por prompt
- **Modelo**: GPT-4o (ou GPT-4o-mini para entreg√°veis)
- **Temperature**: 0.7
- **Max Tokens**: 1.500 (resposta)

### Chamadas LLM por Intera√ß√£o:
- **Conversa normal**: 1 chamada (prompt system + user prompt)
- **Gera√ß√£o de entreg√°veis**: 1 + N chamadas (N = n√∫mero de entreg√°veis)

### Contexto Mantido:
- √öltimas 5 mensagens da conversa
- TODO o contexto_coleta (sem limite)
- Todos os entreg√°veis j√° gerados
- Status de gamifica√ß√£o atual
- Estado de valida√ß√£o

---

## üîí Seguran√ßa

### RLS Implementado:
- ‚úÖ `jornadas_consultor` - Usu√°rios veem apenas suas jornadas
- ‚úÖ `gamificacao_conversa` - Usu√°rios veem apenas suas conversas
- ‚úÖ `timeline_consultor` - Usu√°rios veem apenas seus eventos
- ‚úÖ `entregaveis_consultor` - Usu√°rios veem apenas seus entreg√°veis

### Autentica√ß√£o:
- Edge Function `consultor-chat` tem `verify_jwt: true`
- Requer Authorization header v√°lido
- Service role key usado internamente para opera√ß√µes no banco

---

## üìà M√©tricas e Logs

Todos os logs incluem prefixo `[CONSULTOR-CHAT]`:
- Request recebido
- Jornada criada/encontrada
- Formul√°rio detectado
- Prompt lengths
- LLM chamado
- Marcadores detectados
- Entreg√°veis gerados
- Request completed

---

## Conclus√£o

O sistema est√° **100% implementado** e pronto para uso. A LLM agora √© um **consultor profissional** que:

1. **Conduz** o processo (n√£o pergunta o que fazer)
2. **Segue** o framework estruturado
3. **Explica** cada entreg√°vel gerado
4. **Aguarda** valida√ß√£o do cliente
5. **Usa CTAs** contextualizados
6. **Nunca repete** perguntas
7. **Mant√©m** gamifica√ß√£o natural
8. **Gera** documentos customizados

O cliente tem uma experi√™ncia de **consultoria real com IA**, n√£o um chatbot gen√©rico.
